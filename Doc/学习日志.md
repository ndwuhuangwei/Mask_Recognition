# MobileNet目的

Vgg、Res等的权重文件都太大了，为了在嵌入式设备上部署深度学习模型，发明了MobileNet, 
大大减少了模型参数数量与运算量

MobileNet两个两点
1. Depthwise Convolution(大大减少运算量和参数数量)
2. 增加超参数a, b
    a控制卷积层卷积核个数；b控制输入图像大小
    这两个参数是自定的，不是学习到的
    
# MobileNet详解

## 传统CNN的卷积

![avator](../Doc Pictures/kernal.png)

传统卷积中，输入是三个矩阵，那么一个卷积核深度为3，经过这个卷积层后的输出个数为卷积核个数4

卷积核channel数量 = 输入特征矩阵channel数量
输出特征矩阵数量 = 卷积核个数

DW卷积如下：
    
![avator](../Doc Pictures/DW.png)

# 查看 tensor的值
训练后产生的 loss和 accuracy都是tf.tensor类型
在tf 1代中可以使用 tf.Session来查看tensor数值
在tf 2代中没有 Session了，使用 tensor.numpy()即可查看其数值

# tensorflow2.0 的训练方法
在TensorFlow2.0中，训练一个神经网络模型主要有两种方式：
1. 使用tf.keras模块的Model.fit()；
2. 使用tf.GradientTape()求解梯度，这样可以自定义训练过程